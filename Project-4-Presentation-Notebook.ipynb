{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago West Nile Virus Recommendations\n",
    "## By Brendan Bailey, Robert Miller, and Robert Watkins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in each of the datasets, and performing EDA on them.\n",
    "\n",
    "Due to the spray dataframe only covering half of our train dataframe, we decided to not use the spray dataframe.\n",
    "\n",
    "The weather dataframe had a lot of null values. Some of the null values were coded as \"M\" or \"T\". So we converted them to nulls.\n",
    "\n",
    "Another oddity noticed which we cannot fix is that train data only covers every other year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eda(dataframe): #Performs exploratory data analysis on the dataframe\n",
    "    print \"columns \\n\", dataframe.columns\n",
    "    print \"head \\n\", dataframe.head()\n",
    "    print \"tail \\n\", dataframe.tail()\n",
    "    print \"missing values \\n\", dataframe.isnull().sum()\n",
    "    print \"dataframe types \\n\", dataframe.dtypes\n",
    "    print \"dataframe shape \\n\", dataframe.shape\n",
    "    print \"dataframe describe \\n\", dataframe.describe() #summary statistics\n",
    "    for item in dataframe:\n",
    "        print item\n",
    "        print dataframe[item].nunique()\n",
    "    print \"%s duplicates out of %s records\" % (len(dataframe) - len(dataframe.drop_duplicates()), len(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"assets/train.csv\")\n",
    "weather_df = pd.read_csv(\"assets/weather.csv\")\n",
    "spray_df = pd.read_csv(\"assets/spray.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DF\n",
      "columns \n",
      "Index([u'Date', u'Address', u'Species', u'Block', u'Street', u'Trap',\n",
      "       u'AddressNumberAndStreet', u'Latitude', u'Longitude',\n",
      "       u'AddressAccuracy', u'NumMosquitos', u'WnvPresent'],\n",
      "      dtype='object')\n",
      "head \n",
      "         Date                                            Address  \\\n",
      "0  2007-05-29  4100 North Oak Park Avenue, Chicago, IL 60634,...   \n",
      "1  2007-05-29  4100 North Oak Park Avenue, Chicago, IL 60634,...   \n",
      "2  2007-05-29  6200 North Mandell Avenue, Chicago, IL 60646, USA   \n",
      "3  2007-05-29    7900 West Foster Avenue, Chicago, IL 60656, USA   \n",
      "4  2007-05-29    7900 West Foster Avenue, Chicago, IL 60656, USA   \n",
      "\n",
      "                  Species  Block           Street  Trap  \\\n",
      "0  CULEX PIPIENS/RESTUANS     41   N OAK PARK AVE  T002   \n",
      "1          CULEX RESTUANS     41   N OAK PARK AVE  T002   \n",
      "2          CULEX RESTUANS     62    N MANDELL AVE  T007   \n",
      "3  CULEX PIPIENS/RESTUANS     79     W FOSTER AVE  T015   \n",
      "4          CULEX RESTUANS     79     W FOSTER AVE  T015   \n",
      "\n",
      "              AddressNumberAndStreet   Latitude  Longitude  AddressAccuracy  \\\n",
      "0  4100  N OAK PARK AVE, Chicago, IL  41.954690 -87.800991                9   \n",
      "1  4100  N OAK PARK AVE, Chicago, IL  41.954690 -87.800991                9   \n",
      "2   6200  N MANDELL AVE, Chicago, IL  41.994991 -87.769279                9   \n",
      "3    7900  W FOSTER AVE, Chicago, IL  41.974089 -87.824812                8   \n",
      "4    7900  W FOSTER AVE, Chicago, IL  41.974089 -87.824812                8   \n",
      "\n",
      "   NumMosquitos  WnvPresent  \n",
      "0             1           0  \n",
      "1             1           0  \n",
      "2             1           0  \n",
      "3             1           0  \n",
      "4             4           0  \n",
      "tail \n",
      "             Date                                            Address  \\\n",
      "10501  2013-09-26      5100 West 72nd Street, Chicago, IL 60638, USA   \n",
      "10502  2013-09-26    5800 North Ridge Avenue, Chicago, IL 60660, USA   \n",
      "10503  2013-09-26  1700 North Ashland Avenue, Chicago, IL 60622, USA   \n",
      "10504  2013-09-26   7100 North Harlem Avenue, Chicago, IL 60631, USA   \n",
      "10505  2013-09-26      4200 West 65th Street, Chicago, IL 60621, USA   \n",
      "\n",
      "                      Species  Block          Street  Trap  \\\n",
      "10501  CULEX PIPIENS/RESTUANS     51       W 72ND ST  T035   \n",
      "10502  CULEX PIPIENS/RESTUANS     58     N RIDGE AVE  T231   \n",
      "10503  CULEX PIPIENS/RESTUANS     17   N ASHLAND AVE  T232   \n",
      "10504  CULEX PIPIENS/RESTUANS     71    N HARLEM AVE  T233   \n",
      "10505  CULEX PIPIENS/RESTUANS     42       W 65TH ST  T235   \n",
      "\n",
      "                 AddressNumberAndStreet   Latitude  Longitude  \\\n",
      "10501      5100  W 72ND ST, Chicago, IL  41.763733 -87.742302   \n",
      "10502    5800  N RIDGE AVE, Chicago, IL  41.987280 -87.666066   \n",
      "10503  1700  N ASHLAND AVE, Chicago, IL  41.912563 -87.668055   \n",
      "10504   7100  N HARLEM AVE, Chicago, IL  42.009876 -87.807277   \n",
      "10505      4200  W 65TH ST, Chicago, IL  41.776428 -87.627096   \n",
      "\n",
      "       AddressAccuracy  NumMosquitos  WnvPresent  \n",
      "10501                8             6           1  \n",
      "10502                8             5           0  \n",
      "10503                9             1           0  \n",
      "10504                9             5           0  \n",
      "10505                8             1           0  \n",
      "missing values \n",
      "Date                      0\n",
      "Address                   0\n",
      "Species                   0\n",
      "Block                     0\n",
      "Street                    0\n",
      "Trap                      0\n",
      "AddressNumberAndStreet    0\n",
      "Latitude                  0\n",
      "Longitude                 0\n",
      "AddressAccuracy           0\n",
      "NumMosquitos              0\n",
      "WnvPresent                0\n",
      "dtype: int64\n",
      "dataframe types \n",
      "Date                       object\n",
      "Address                    object\n",
      "Species                    object\n",
      "Block                       int64\n",
      "Street                     object\n",
      "Trap                       object\n",
      "AddressNumberAndStreet     object\n",
      "Latitude                  float64\n",
      "Longitude                 float64\n",
      "AddressAccuracy             int64\n",
      "NumMosquitos                int64\n",
      "WnvPresent                  int64\n",
      "dtype: object\n",
      "dataframe shape \n",
      "(10506, 12)\n",
      "dataframe describe \n",
      "              Block      Latitude     Longitude  AddressAccuracy  \\\n",
      "count  10506.000000  10506.000000  10506.000000     10506.000000   \n",
      "mean      35.687797     41.841139    -87.699908         7.819532   \n",
      "std       24.339468      0.112742      0.096514         1.452921   \n",
      "min       10.000000     41.644612    -87.930995         3.000000   \n",
      "25%       12.000000     41.732984    -87.760070         8.000000   \n",
      "50%       33.000000     41.846283    -87.694991         8.000000   \n",
      "75%       52.000000     41.954690    -87.627796         9.000000   \n",
      "max       98.000000     42.017430    -87.531635         9.000000   \n",
      "\n",
      "       NumMosquitos    WnvPresent  \n",
      "count  10506.000000  10506.000000  \n",
      "mean      12.853512      0.052446  \n",
      "std       16.133816      0.222936  \n",
      "min        1.000000      0.000000  \n",
      "25%        2.000000      0.000000  \n",
      "50%        5.000000      0.000000  \n",
      "75%       17.000000      0.000000  \n",
      "max       50.000000      1.000000  \n",
      "Date\n",
      "95\n",
      "Address\n",
      "138\n",
      "Species\n",
      "7\n",
      "Block\n",
      "64\n",
      "Street\n",
      "128\n",
      "Trap\n",
      "136\n",
      "AddressNumberAndStreet\n",
      "138\n",
      "Latitude\n",
      "138\n",
      "Longitude\n",
      "138\n",
      "AddressAccuracy\n",
      "4\n",
      "NumMosquitos\n",
      "50\n",
      "WnvPresent\n",
      "2\n",
      "813 duplicates out of 10506 records\n",
      "None\n",
      "Weather DF\n",
      "columns \n",
      "Index([u'Station', u'Date', u'Tmax', u'Tmin', u'Tavg', u'Depart', u'DewPoint',\n",
      "       u'WetBulb', u'Heat', u'Cool', u'Sunrise', u'Sunset', u'CodeSum',\n",
      "       u'Depth', u'Water1', u'SnowFall', u'PrecipTotal', u'StnPressure',\n",
      "       u'SeaLevel', u'ResultSpeed', u'ResultDir', u'AvgSpeed'],\n",
      "      dtype='object')\n",
      "head \n",
      "   Station        Date  Tmax  Tmin Tavg Depart  DewPoint WetBulb Heat Cool  \\\n",
      "0        1  2007-05-01    83    50   67     14        51      56    0    2   \n",
      "1        2  2007-05-01    84    52   68      M        51      57    0    3   \n",
      "2        1  2007-05-02    59    42   51     -3        42      47   14    0   \n",
      "3        2  2007-05-02    60    43   52      M        42      47   13    0   \n",
      "4        1  2007-05-03    66    46   56      2        40      48    9    0   \n",
      "\n",
      "     ...    CodeSum Depth Water1 SnowFall PrecipTotal StnPressure SeaLevel  \\\n",
      "0    ...                0      M      0.0        0.00       29.10    29.82   \n",
      "1    ...                M      M        M        0.00       29.18    29.82   \n",
      "2    ...         BR     0      M      0.0        0.00       29.38    30.09   \n",
      "3    ...      BR HZ     M      M        M        0.00       29.44    30.08   \n",
      "4    ...                0      M      0.0        0.00       29.39    30.12   \n",
      "\n",
      "  ResultSpeed ResultDir  AvgSpeed  \n",
      "0         1.7        27       9.2  \n",
      "1         2.7        25       9.6  \n",
      "2        13.0         4      13.4  \n",
      "3        13.3         2      13.4  \n",
      "4        11.7         7      11.9  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "tail \n",
      "      Station        Date  Tmax  Tmin Tavg Depart  DewPoint WetBulb Heat Cool  \\\n",
      "2939        2  2014-10-29    49    40   45      M        34      42   20    0   \n",
      "2940        1  2014-10-30    51    32   42     -4        34      40   23    0   \n",
      "2941        2  2014-10-30    53    37   45      M        35      42   20    0   \n",
      "2942        1  2014-10-31    47    33   40     -6        25      33   25    0   \n",
      "2943        2  2014-10-31    49    34   42      M        29      36   23    0   \n",
      "\n",
      "        ...      CodeSum Depth Water1 SnowFall PrecipTotal StnPressure  \\\n",
      "2939    ...                  M      M        M        0.00       29.42   \n",
      "2940    ...                  0      M      0.0        0.00       29.34   \n",
      "2941    ...           RA     M      M        M           T       29.41   \n",
      "2942    ...        RA SN     0      M      0.1        0.03       29.49   \n",
      "2943    ...     RA SN BR     M      M        M        0.04       29.54   \n",
      "\n",
      "     SeaLevel ResultSpeed ResultDir  AvgSpeed  \n",
      "2939    30.07         8.5        29       9.0  \n",
      "2940    30.09         5.1        24       5.5  \n",
      "2941    30.10         5.9        23       6.5  \n",
      "2942    30.20        22.6        34      22.9  \n",
      "2943    30.20        21.7        34      22.6  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "missing values \n",
      "Station        0\n",
      "Date           0\n",
      "Tmax           0\n",
      "Tmin           0\n",
      "Tavg           0\n",
      "Depart         0\n",
      "DewPoint       0\n",
      "WetBulb        0\n",
      "Heat           0\n",
      "Cool           0\n",
      "Sunrise        0\n",
      "Sunset         0\n",
      "CodeSum        0\n",
      "Depth          0\n",
      "Water1         0\n",
      "SnowFall       0\n",
      "PrecipTotal    0\n",
      "StnPressure    0\n",
      "SeaLevel       0\n",
      "ResultSpeed    0\n",
      "ResultDir      0\n",
      "AvgSpeed       0\n",
      "dtype: int64\n",
      "dataframe types \n",
      "Station          int64\n",
      "Date            object\n",
      "Tmax             int64\n",
      "Tmin             int64\n",
      "Tavg            object\n",
      "Depart          object\n",
      "DewPoint         int64\n",
      "WetBulb         object\n",
      "Heat            object\n",
      "Cool            object\n",
      "Sunrise         object\n",
      "Sunset          object\n",
      "CodeSum         object\n",
      "Depth           object\n",
      "Water1          object\n",
      "SnowFall        object\n",
      "PrecipTotal     object\n",
      "StnPressure     object\n",
      "SeaLevel        object\n",
      "ResultSpeed    float64\n",
      "ResultDir        int64\n",
      "AvgSpeed        object\n",
      "dtype: object\n",
      "dataframe shape \n",
      "(2944, 22)\n",
      "dataframe describe \n",
      "           Station         Tmax         Tmin     DewPoint  ResultSpeed  \\\n",
      "count  2944.000000  2944.000000  2944.000000  2944.000000  2944.000000   \n",
      "mean      1.500000    76.166101    57.810462    53.457880     6.960666   \n",
      "std       0.500085    11.461970    10.381939    10.675181     3.587527   \n",
      "min       1.000000    41.000000    29.000000    22.000000     0.100000   \n",
      "25%       1.000000    69.000000    50.000000    46.000000     4.300000   \n",
      "50%       1.500000    78.000000    59.000000    54.000000     6.400000   \n",
      "75%       2.000000    85.000000    66.000000    62.000000     9.200000   \n",
      "max       2.000000   104.000000    83.000000    75.000000    24.100000   \n",
      "\n",
      "         ResultDir  \n",
      "count  2944.000000  \n",
      "mean     17.494905  \n",
      "std      10.063609  \n",
      "min       1.000000  \n",
      "25%       7.000000  \n",
      "50%      19.000000  \n",
      "75%      25.000000  \n",
      "max      36.000000  \n",
      "Station\n",
      "2\n",
      "Date\n",
      "1472\n",
      "Tmax\n",
      "63\n",
      "Tmin\n",
      "54\n",
      "Tavg\n",
      "60\n",
      "Depart\n",
      "42\n",
      "DewPoint\n",
      "54\n",
      "WetBulb\n",
      "48\n",
      "Heat\n",
      "31\n",
      "Cool\n",
      "31\n",
      "Sunrise\n",
      "122\n",
      "Sunset\n",
      "119\n",
      "CodeSum\n",
      "98\n",
      "Depth\n",
      "2\n",
      "Water1\n",
      "1\n",
      "SnowFall\n",
      "4\n",
      "PrecipTotal\n",
      "168\n",
      "StnPressure\n",
      "104\n",
      "SeaLevel\n",
      "102\n",
      "ResultSpeed\n",
      "190\n",
      "ResultDir\n",
      "36\n",
      "AvgSpeed\n",
      "178\n",
      "0 duplicates out of 2944 records\n",
      "None\n",
      "Spray DF\n",
      "columns \n",
      "Index([u'Date', u'Time', u'Latitude', u'Longitude'], dtype='object')\n",
      "head \n",
      "         Date        Time   Latitude  Longitude\n",
      "0  2011-08-29  6:56:58 PM  42.391623 -88.089163\n",
      "1  2011-08-29  6:57:08 PM  42.391348 -88.089163\n",
      "2  2011-08-29  6:57:18 PM  42.391022 -88.089157\n",
      "3  2011-08-29  6:57:28 PM  42.390637 -88.089158\n",
      "4  2011-08-29  6:57:38 PM  42.390410 -88.088858\n",
      "tail \n",
      "             Date        Time   Latitude  Longitude\n",
      "14830  2013-09-05  8:34:11 PM  42.006587 -87.812355\n",
      "14831  2013-09-05  8:35:01 PM  42.006192 -87.816015\n",
      "14832  2013-09-05  8:35:21 PM  42.006022 -87.817392\n",
      "14833  2013-09-05  8:35:31 PM  42.005453 -87.817423\n",
      "14834  2013-09-05  8:35:41 PM  42.004805 -87.817460\n",
      "missing values \n",
      "Date           0\n",
      "Time         584\n",
      "Latitude       0\n",
      "Longitude      0\n",
      "dtype: int64\n",
      "dataframe types \n",
      "Date          object\n",
      "Time          object\n",
      "Latitude     float64\n",
      "Longitude    float64\n",
      "dtype: object\n",
      "dataframe shape \n",
      "(14835, 4)\n",
      "dataframe describe \n",
      "           Latitude     Longitude\n",
      "count  14835.000000  14835.000000\n",
      "mean      41.904828    -87.736690\n",
      "std        0.104381      0.067292\n",
      "min       41.713925    -88.096468\n",
      "25%       41.785001    -87.794225\n",
      "50%       41.940075    -87.727853\n",
      "75%       41.980978    -87.694108\n",
      "max       42.395983    -87.586727\n",
      "Date\n",
      "10\n",
      "Time\n",
      "8583\n",
      "Latitude\n",
      "12887\n",
      "Longitude\n",
      "13007\n",
      "541 duplicates out of 14835 records\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print \"Train DF\\n\", eda(train_df)\n",
    "print \"Weather DF\\n\", eda(weather_df)\n",
    "print \"Spray DF\\n\", eda(spray_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to correcting the problems seen during EDA, we rolled up the train data set which has multiple records for any date and box that has a mosquito count that exceeds 50, converted all columns to the appropriate data type, and joined the new train dataframe to the weather dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_and_transform(train, weather):\n",
    "    #Replacing M which is missing data and T which is Trace Data with NAN\n",
    "    weather_df.replace(\"M\", np.nan, inplace = True)\n",
    "    weather_df.replace(\"T\", np.nan, inplace = True)\n",
    "    \n",
    "    #Casting all appropriate weather columns as ints\n",
    "    numeric_columns = ['Station', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb', 'Heat', 'Cool', 'Sunrise', 'Sunset', 'Depth', 'Water1', 'SnowFall', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed']\n",
    "    for column in numeric_columns:\n",
    "        weather_df[column] = weather_df[column].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    #Imputing Data for WetBulb and StnPressure\n",
    "    wetbulb_median = np.median(weather_df.dropna(subset = [\"WetBulb\"]).WetBulb)\n",
    "    stnpressure_median = np.median(weather_df.dropna(subset = [\"StnPressure\"]).StnPressure)\n",
    "    weather_df.WetBulb.fillna(np.median(wetbulb_median), inplace = True)\n",
    "    weather_df.StnPressure.fillna(np.median(stnpressure_median), inplace = True)\n",
    "    \n",
    "    #Rolling up Data so only one record for date and trap available, and also adding spray location based on Date and Location\n",
    "    train[\"Date-Trap\"] = train[\"Date\"] + \"-\" + train[\"Trap\"]\n",
    "    target_remap_dict = {}\n",
    "    for index, row in train[[\"Date-Trap\", \"WnvPresent\", \"Species\"]].iterrows():\n",
    "        #Checking for WNV Mosquito Species\n",
    "        if row[\"Species\"] in [\"CULEX PIPIENS/RESTUANS\", \"CULEX RESTUANS\", \"CULEX PIPIENS\"]:\n",
    "            wnv_mosquitos = 1\n",
    "        else:\n",
    "            wnv_mosquitos = 0\n",
    "        #Updating Dictionary\n",
    "        try:\n",
    "            if target_remap_dict[row[\"Date-Trap\"]][\"WnvPresentAdj\"] == 0:\n",
    "                target_remap_dict[row[\"Date-Trap\"]][\"WnvPresentAdj\"] = row[\"WnvPresent\"]\n",
    "            if target_remap_dict[row[\"Date-Trap\"]][\"WnvMosquito\"] == 0:\n",
    "                target_remap_dict[row[\"Date-Trap\"]][\"WnvMosquito\"] = wnv_mosquitos\n",
    "        except KeyError: \n",
    "            target_remap_dict[row[\"Date-Trap\"]] = {\"WnvPresentAdj\": row[\"WnvPresent\"], \"WnvMosquito\": wnv_mosquitos}\n",
    "    target_remap_df = pd.DataFrame.from_dict(target_remap_dict, orient = \"index\")\n",
    "    \n",
    "    master_df = train.drop_duplicates(subset = [\"Date\", \"Trap\"])\n",
    "    del master_df['WnvPresent']\n",
    "    del master_df['Species']\n",
    "    master_df = pd.merge(master_df, target_remap_df, left_on = \"Date-Trap\", right_index = True)\n",
    "    master_df = pd.merge(master_df, weather[weather.Station == 1], left_on = \"Date\", right_on = \"Date\", how = \"left\")\n",
    "    del master_df[\"Date-Trap\"]\n",
    "    \n",
    "    #Getting Block Dummies\n",
    "    block_dummies = pd.get_dummies(master_df.Block)\n",
    "    master_df = pd.merge(master_df, block_dummies, left_index = True, right_index = True)\n",
    "    \n",
    "    #Converting Date from string to date. The df only has data for odd years which is weird!\n",
    "    master_df[\"Date\"] = pd.to_datetime(master_df.Date)\n",
    "    \n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df = clean_and_transform(train_df, weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv(\"master_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we created our ADABoost Model. We lowered the threshold for predicting a positive to 0.498 to help correct for false negatives.\n",
    "\n",
    "In our train set we get an accuracy of 80%, sensitivity of 100%, and a specificity of 78%.\n",
    "\n",
    "In our test set we get an accuracy of 76%, sensitivity of 75%, and a specificity of 76%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X = master_df.drop(['WnvPresentAdj', 'CodeSum', 'AddressNumberAndStreet', 'Date', 'Address','Street','Trap','Water1','PrecipTotal', 'SnowFall', 'Block', 96, 93, 98, \"NumMosquitos\"], axis=1)#[['NumMosquitos', 'Cool', 'DewPoint', 'Sunrise','Heat', 'Tmax', 'Depart', 'WetBulb']]\n",
    "#X_scaled = preprocessing.normalize(X,axis=0)\n",
    "X = master_df[[\"Block\", \"Tmax\", \"Tmin\", \"Tavg\", \"Depart\", \"DewPoint\", \"WetBulb\", \"Heat\", \"Cool\", \"Sunrise\", \"Sunset\", \"StnPressure\", \"SeaLevel\", \"ResultSpeed\", \"ResultDir\", \"AvgSpeed\"]]\n",
    "y = master_df.WnvPresentAdj\n",
    "names = ['has westnile', \"doesn't have westnile\", \"pred westnile\", \"predicted doesnt have westnile\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(model, X_scaled,y,names):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify = y, train_size=.7, random_state = 626718) \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #Train Set Evaluation\n",
    "    train_predictions = model.predict_proba(X_train)\n",
    "    train_adjusted_predict = [1 if x[1] > .48 else 0 for x in train_predictions]\n",
    "    train_conmat = np.array(confusion_matrix(y_train, train_adjusted_predict, labels = [1,0]))\n",
    "    train_confusion = pd.DataFrame(train_conmat, index=[names[0:2]], columns =[names[2:]])\n",
    "    print \"Train Eval\"\n",
    "    print train_confusion\n",
    "    train_acc = accuracy_score(y_train, train_adjusted_predict)\n",
    "    print(classification_report(y_train, train_adjusted_predict))\n",
    "    print train_acc\n",
    "    \n",
    "    #Test Set Evaluation\n",
    "    test_predictions = model.predict_proba(X_test)\n",
    "    test_adjusted_predict = [1 if x[1] > .48 else 0 for x in test_predictions]\n",
    "    test_conmat = np.array(confusion_matrix(y_test, test_adjusted_predict, labels = [1,0]))\n",
    "    test_confusion = pd.DataFrame(test_conmat, index=[names[0:2]], columns =[names[2:]])\n",
    "    print \"Test Eval\"\n",
    "    print test_confusion\n",
    "    test_acc = accuracy_score(y_test, test_adjusted_predict)\n",
    "    print(classification_report(y_test, test_adjusted_predict))\n",
    "    print test_acc\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state = 98574, n_estimators = 50, max_depth = 5, max_features = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Eval\n",
      "                       pred westnile  predicted doesnt have westnile\n",
      "has westnile                     269                               0\n",
      "doesn't have westnile            645                            2317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88      2962\n",
      "          1       0.29      1.00      0.45       269\n",
      "\n",
      "avg / total       0.94      0.80      0.84      3231\n",
      "\n",
      "0.800371402043\n",
      "Test Eval\n",
      "                       pred westnile  predicted doesnt have westnile\n",
      "has westnile                      87                              29\n",
      "doesn't have westnile            305                             964\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.76      0.85      1269\n",
      "          1       0.22      0.75      0.34       116\n",
      "\n",
      "avg / total       0.91      0.76      0.81      1385\n",
      "\n",
      "0.758844765343\n"
     ]
    }
   ],
   "source": [
    "model = create_model(AdaBoostClassifier(forest, n_estimators = 100, random_state = 918064), X, y, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the model to our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"assets/test.csv.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting our initial clean and transform function which rolls up dates and traps into one record each. We want to have the same number of predictions equal to test set size, so we're deleting that functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_and_transform_final(train, weather):\n",
    "    #Replacing M which is missing data and T which is Trace Data with NAN\n",
    "    weather_df.replace(\"M\", np.nan, inplace = True)\n",
    "    weather_df.replace(\"T\", np.nan, inplace = True)\n",
    "    \n",
    "    #Casting all appropriate weather columns as ints\n",
    "    numeric_columns = ['Station', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb', 'Heat', 'Cool', 'Sunrise', 'Sunset', 'Depth', 'Water1', 'SnowFall', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed']\n",
    "    for column in numeric_columns:\n",
    "        weather_df[column] = weather_df[column].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    #Imputing Data for WetBulb and StnPressure\n",
    "    wetbulb_median = np.median(weather_df.dropna(subset = [\"WetBulb\"]).WetBulb)\n",
    "    stnpressure_median = np.median(weather_df.dropna(subset = [\"StnPressure\"]).StnPressure)\n",
    "    weather_df.WetBulb.fillna(np.median(wetbulb_median), inplace = True)\n",
    "    weather_df.StnPressure.fillna(np.median(stnpressure_median), inplace = True)\n",
    "    \n",
    "    #Rolling up Data so only one record for date and trap available, and also adding spray location based on Date and Location\n",
    "    train[\"Date-Trap\"] = train[\"Date\"] + \"-\" + train[\"Trap\"]\n",
    "    target_remap_dict = {}\n",
    "    for index, row in train[[\"Date-Trap\", \"Species\"]].iterrows():\n",
    "        #Checking for WNV Mosquito Species\n",
    "        if row[\"Species\"] in [\"CULEX PIPIENS/RESTUANS\", \"CULEX RESTUANS\", \"CULEX PIPIENS\"]:\n",
    "            wnv_mosquitos = 1\n",
    "        else:\n",
    "            wnv_mosquitos = 0\n",
    "        #Updating Dictionary\n",
    "        try:\n",
    "            if target_remap_dict[row[\"Date-Trap\"]][\"WnvMosquito\"] == 0:\n",
    "                target_remap_dict[row[\"Date-Trap\"]][\"WnvMosquito\"] = wnv_mosquitos\n",
    "        except KeyError: \n",
    "            target_remap_dict[row[\"Date-Trap\"]] = {\"WnvMosquito\": wnv_mosquitos}\n",
    "    target_remap_df = pd.DataFrame.from_dict(target_remap_dict, orient = \"index\")\n",
    "    \n",
    "    master_df = pd.merge(test_df, target_remap_df, left_on = \"Date-Trap\", right_index = True)\n",
    "    master_df = pd.merge(master_df, weather[weather.Station == 1], left_on = \"Date\", right_on = \"Date\", how = \"left\")\n",
    "    del master_df['Species']\n",
    "    del master_df[\"Date-Trap\"]\n",
    "    \n",
    "    #Getting Block Dummies\n",
    "    block_dummies = pd.get_dummies(master_df.Block)\n",
    "    master_df = pd.merge(master_df, block_dummies, left_index = True, right_index = True)\n",
    "    \n",
    "    #Converting Date from string to date. The df only has data for odd years which is weird!\n",
    "    master_df[\"Date\"] = pd.to_datetime(master_df.Date)\n",
    "    \n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_test = clean_and_transform_final(test_df, weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_final = master_test[X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end we predict 9,467 records out of 116,293 are predicted to have West Nile virus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9467 records out of 116293 predicted to have West Nile\n"
     ]
    }
   ],
   "source": [
    "final_predictions = model.predict_proba(X_final)\n",
    "final_adjusted_predict = [1 if x[1] > .48 else 0 for x in final_predictions]\n",
    "print \"%s records out of %s predicted to have West Nile\" % (sum(final_adjusted_predict), len(final_adjusted_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below saving the results into a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_adjusted_predict_df = pd.DataFrame(final_adjusted_predict, columns = [\"Predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_test_csv = pd.merge(master_test, final_adjusted_predict_df, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_test_csv.to_csv(\"final_test_set.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
